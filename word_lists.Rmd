---
title: "Developing Target Lists for Analysis"
author: "Ben Kubacki"
date: "16 November 2024"
output: 
  github_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, include=TRUE, comment="", fig.path = "images/")
library(tidyverse)
library(dplyr)
library(purrr)
library(stringr)
library(readxl)
library(ggplot2)

# web scraping
library(rvest)

# tokenizer
library(tidytext)


```

[Link to data download: Academic "core"](https://www.academicwords.info/download.asp)

# COCA Frequency Lists

## Subgenre codes

```{r}

# subgenres_news <- read_delim("../data_private/subgenreCodes.txt", col_names = F) %>% 
  # rename(code = X1, subgenre = X2) %>%  
  # filter(code %in% 135:142)


```

## Academic Core List

Read the data in

```{r}

# academic_core <- read_excel("data_private/acadCore.xlsx", sheet = 2)

```


## b1407 XLSX 100k

This is word frequency data that may be useful. However, it is only displaying the first "sheet" of the Excel file, so I may need to modify that before reading it in.

I deleted this data from the project directory for now, so the code won't work.

```{r}

# freq_100k_excel <- read_excel("../data_private/data_unzipped_freq_100k/b1407/b1407.xlsx", skip = 0, sheet = 2) 
# 
# freq_100k_excel %>% slice(1:20)
# 
# colnames(freq_100k_excel) %>% 
#   str_subset("coca")

```


# web-scraping vocab lists

```{r}
gorick_list <- read_html("https://www.gorick.com/blog/workplace-jargon-dictionary")

gorick_list <- gorick_list %>%
  html_elements("h3") %>%
  html_text()


gorick_list <- gorick_list %>%
  str_remove("^.") %>%
  str_remove(".$")


## Try to get this to remove strings with acronyms and maybe numbers
gorick_list <- gorick_list %>%
  str_subset("^[A-Z]{2,9}$", negate=T) %>%
  str_subset("^[A-Z]{")

gorick_list <- gorick_list %>%
  tolower()

gorick_tbl <- tibble(word = gorick_list)

gorick_tbl %>% slice(1:20)
 
```

How to remove strings with acronyms from Gorick list

```{r}
test_acronyms <- c("A", "AB", "BC", "DEF", "GHIJ", "ab", "bc", "def", "ghij", "Ab", "bC", "DeF", "GHij")
test_acronyms %>% 
  str_view("[ABCDEFGHIJKLMNOPQRSTUVWXYZ]{2}+") ## Returns any two capitals (misses strings of more than two)
test_acronyms %>% 
  str_view("[ABCDEFGHIJKLMNOPQRSTUVWXYZ]+") ## returns all capitals not isolated acronyms
test_acronyms %>% 
  str_view("[ABCDEFGHIJKLMNOPQRSTUVWXYZ]+") ## 
unlist(str_extract_all(test_acronyms,"[ABCDEFGHIJKLMNOPQRSTUVWXYZ]{2}+"))
list(str_extract_all(test_acronyms,"[ABCDEFGHIJKLMNOPQRSTUVWXYZ]{2}+"))
test_acronyms %>% 
  str_subset("[A-Z]{2}+") ## Returns any whole string with at least two adjacent capitals 

test_acronyms %>% 
  str_view("^[A-Z]{2,9}$") ## GOLD. Returns strings with only a series of capitals between 2 and 9, but nothing after or before it (i.e., lowercase letters)


  
```


## Promova list

```{r}

promova_list <- read_html("https://promova.com/english-vocabulary/occupations-and-jobs-english-vocabulary") %>% 
  html_elements("li span") %>% 
  html_text()

promova_list <- promova_list[10:63] %>% 
  str_extract("^.+\\:") %>% 
  str_to_lower %>% 
  str_remove("\\:")

promova_list <- promova_list[27:54] 

# promova_list <- promova_list %>%
#   str_remove("ing")

promova_table <- promova_list %>% 
  tibble(word = `.`) 

stoplist <- c("cover letter", "job description", "background check", "probationary period", "job offer", "telecommuting/remote working", "salary expectations", "out of office")

promova_table <- promova_table %>% 
  filter(!word %in% stoplist)

promova_table$word <- promova_table$word %>% 
  str_remove("ing")

```


# Session info

```{r}
sessionInfo()
```
